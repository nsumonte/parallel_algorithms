{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXU0X3HC12PN"
      },
      "source": [
        "#TAREA 4\n",
        "Nombre: Nicolás Sumonte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5O4dNDW16o5"
      },
      "source": [
        "- En primer lugar, importamos PyopenCl y otras librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcW3ssnZUxcp",
        "outputId": "b22f554a-503d-4176-b288-d6f573ac8391"
      },
      "source": [
        "!pip install pyopencl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyopencl in /usr/local/lib/python3.7/dist-packages (2021.2.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyopencl) (1.19.5)\n",
            "Requirement already satisfied: pytools>=2021.2.7 in /usr/local/lib/python3.7/dist-packages (from pyopencl) (2021.2.9)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyopencl) (1.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbTL10BgZGe4"
      },
      "source": [
        "import numpy as np\n",
        "from time import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyRNrBfg2COr"
      },
      "source": [
        "- Usamos la función dada en la tarea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EniskKZng2DB"
      },
      "source": [
        "def generate_matrix(dim):\n",
        "  from scipy.stats import ortho_group\n",
        "  from scipy.sparse import spdiags\n",
        "  a = ortho_group.rvs(dim, random_state=0)\n",
        "  b = np.linspace(1., 10., dim)\n",
        "  return a @ spdiags(b, 0, dim, dim) @ a.T"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkv-V2wI2FdR"
      },
      "source": [
        "- definimos el metodo de la potencia, utilizando delta la medida de error, iteracion a iteración para terminar el algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfh72p_Ofi_o"
      },
      "source": [
        "def power_method_numpy(A, b0, delta):\n",
        "  mu = 0\n",
        "  while True:\n",
        "    Ab = np.dot(A,b0)\n",
        "    btb = np.dot(np.transpose(b0),b0)\n",
        "    btAb = np.dot(np.transpose(b0),Ab)\n",
        "    mu_new = btAb / btb\n",
        "    norm = np.linalg.norm(Ab)\n",
        "    b0 = Ab / norm\n",
        "    if np.abs(mu - mu_new) < delta:\n",
        "      break\n",
        "    else:\n",
        "      mu = mu_new\n",
        "  return mu"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojdItzpIhMMD"
      },
      "source": [
        "A = generate_matrix(1000)\n",
        "b = np.ones(1000)\n",
        "delta = 0.001"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVqE_UAi2NQu"
      },
      "source": [
        "- Vemos el resultado del metodo de la potencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu3BzWkHhoaz",
        "outputId": "1f29a9f0-a2c1-4080-e2c7-62b198197836"
      },
      "source": [
        "power_method_numpy(A,b,delta)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.938052941072023"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd_dFxCV2QnO"
      },
      "source": [
        "- Implementamos el método con Pyopencl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYt-sIZikoyl",
        "outputId": "587437cd-8b08-4bcd-f1da-61f0e05e78a8"
      },
      "source": [
        "import pyopencl as cl\n",
        "import pyopencl.array as cl_array\n",
        "platform = cl.get_platforms()[0]\n",
        "device = platform.get_devices(cl.device_type.GPU)[0]\n",
        "print(\"Platform name:\", platform.name)\n",
        "print(\"Device name:\", device.name)\n",
        "print(\"Maximum work group size:\", device.max_work_group_size)\n",
        "platforms = cl.get_platforms()\n",
        "ctx = cl.Context(dev_type=cl.device_type.GPU, properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
        "\n",
        "queue = cl.CommandQueue(ctx)\n",
        "workgroup_size = 30\n",
        "n_workgroups = 8\n",
        "matrix_size = 1000\n",
        "\n",
        "A = generate_matrix(matrix_size)\n",
        "b = np.ones(matrix_size)\n",
        " ### función que realiza el padding de los datos\n",
        "def padding(A, b, workgroup_size, matrix_size):\n",
        "  matrix_size_new = matrix_size\n",
        "  if matrix_size_new % workgroup_size == 0:\n",
        "    return A,b,matrix_size_new\n",
        "  else:\n",
        "    while matrix_size_new % workgroup_size != 0:\n",
        "      b = np.append(b,0)\n",
        "      A = np.c_[A, np.zeros(matrix_size)] \n",
        "      matrix_size_new +=1\n",
        "    return A, b, matrix_size_new\n",
        "\n",
        "print(\"\\nWorkgroup size:\", workgroup_size)\n",
        "print(\"Matrix size:\", matrix_size)\n",
        "kernel = \"\"\"\n",
        "__kernel void matvec(__global double *matrix,\n",
        "                     __global double *vector,\n",
        "                     __global double *output\n",
        "                     )\n",
        "{\n",
        "  int dim = get_global_size(0);\n",
        "  int global_id = get_global_id(0);\n",
        "  double local_sum = 0.0;\n",
        "  int offset = global_id * dim;\n",
        "  for(int i = 0; i < dim; i++){\n",
        "    local_sum += matrix[i + offset] * vector[i];\n",
        "  }\n",
        "  output[global_id] = local_sum;\n",
        "}\n",
        "__kernel void norm_calc(__global double *res, __global double *res1)\n",
        "{\n",
        "  int dim = get_global_size(0);\n",
        "  int global_id = get_global_id(0);\n",
        "  double sqrt_sum = 0.0;\n",
        "  for (int i = 0; i < dim; i++)\n",
        "  {\n",
        "    sqrt_sum += res[i]*res[i];\n",
        "  }\n",
        "  barrier(CLK_LOCAL_MEM_FENCE);\n",
        "  res1[0] = sqrt(sqrt_sum);\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "A, b, matrix_size = padding(A,b, workgroup_size, matrix_size)\n",
        "result = np.zeros(matrix_size)\n",
        "result_1 = np.zeros(1)\n",
        "prg = cl.Program(ctx, kernel).build()\n",
        "cl_matrix = cl_array.to_device(queue, A.ravel())\n",
        "cl_vector = cl_array.to_device(queue, b)\n",
        "cl_AB = cl_array.empty(queue, matrix_size, dtype=np.float64)\n",
        "cl_maxvec = cl_array.empty(queue, 1, dtype = np.float64)\n",
        "\n",
        "def opencl_grad(itr,A,b,matrix_size):\n",
        "  counter = 0\n",
        "  times_1 = []\n",
        "  times_2 = []\n",
        "  while counter < itr:\n",
        "    t0 = time()\n",
        "    event = prg.matvec(queue,\n",
        "                       (matrix_size,), (workgroup_size,),\n",
        "                       cl_matrix.data, cl_vector.data, cl_AB.data)\n",
        "    t1 = time()\n",
        "    times_1.append(np.abs(t0 - t1))\n",
        "    events = [event]\n",
        "    cl.enqueue_copy(queue, result, cl_AB.data, wait_for=events);\n",
        "    Ab = result\n",
        "    btb = np.dot(np.transpose(b),b)\n",
        "    btAb = np.dot(np.transpose(b),Ab)\n",
        "    t2 = time()\n",
        "    event = prg.norm_calc(queue,\n",
        "                          (matrix_size,), (workgroup_size,),\n",
        "                          cl_vector.data, cl_maxvec.data)\n",
        "    t4 = time()\n",
        "    times_2.append(np.abs(t2 - t4))\n",
        "    events = [event]\n",
        "    result_1 = cl_maxvec.get()[0]\n",
        "    b = Ab / result_1\n",
        "    mu = btAb / btb\n",
        "    cl.enqueue_copy(queue, cl_vector.data, b, wait_for=events);\n",
        "    counter += 1\n",
        "  time1 = sum(times_1) / len(times_1)\n",
        "  time2 = sum(times_2) / len(times_2)\n",
        "  return mu, time1, time2"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Platform name: NVIDIA CUDA\n",
            "Device name: Tesla K80\n",
            "Maximum work group size: 1024\n",
            "\n",
            "Workgroup size: 30\n",
            "Matrix size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ5DS0cA2b4h"
      },
      "source": [
        "- Aplicamos el metodo con 1500 iteraciones e imprimimos el error del método y los tiempos promedios dentro de los kernels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvZ2GTOusaUi",
        "outputId": "acb4b393-b98f-457c-bcd0-df8e66acf708"
      },
      "source": [
        "mu_by_pyopencl,time1,time2 = opencl_grad(1500, A, b, matrix_size)\n",
        "error = 10 - mu_by_pyopencl\n",
        "print(f'el error de pyopencl es: {error}')\n",
        "print(f'el tiempo promedio dentro del kernel multiplicación es: {time1}')\n",
        "print(f'el tiempo promedio dentro del kernel de norma es : {time2}')\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1020\n",
            "el error de pyopencl es: 0.008050345991511776\n",
            "el tiempo promedio dentro del kernel multiplicación es: 0.00011555226643880209\n",
            "el tiempo promedio dentro del kernel de norma es : 0.00011650196711222331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo_5Xnuv2iMD"
      },
      "source": [
        "- Definimos la función analizar metodos que nos permite calcular los tiempos de distintos metodos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmBm-A3ksjSQ"
      },
      "source": [
        "def analizar_metodos(dim_matrix, workgroupsize,itr):\n",
        "\n",
        "  matrix_size_1 = dim_matrix\n",
        "  A = generate_matrix(matrix_size_1)\n",
        "  b = np.ones(matrix_size_1)\n",
        "  t0 = time()\n",
        "  power_method_numpy(A,b,delta)\n",
        "  t1 = time()\n",
        "  tiempo_power = t1 - t0\n",
        "  print(f'power method tarda: {tiempo_power}')\n",
        "\n",
        "  platform = cl.get_platforms()[0]\n",
        "  device = platform.get_devices(cl.device_type.GPU)[0]\n",
        "  platforms = cl.get_platforms()\n",
        "  ctx = cl.Context(dev_type=cl.device_type.GPU, properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
        "  queue = cl.CommandQueue(ctx)\n",
        "\n",
        "  workgroup_size = workgroupsize\n",
        "  n_workgroups = 8\n",
        "\n",
        "  A, b, matrix_size = padding(A, b, workgroup_size, matrix_size_1)\n",
        "  result = np.zeros(matrix_size)\n",
        "  result_1 = np.zeros(1)\n",
        "  prg = cl.Program(ctx, kernel).build()\n",
        "  cl_matrix = cl_array.to_device(queue, A.ravel())\n",
        "  cl_vector = cl_array.to_device(queue, b)\n",
        "  cl_AB = cl_array.empty(queue, matrix_size, dtype=np.float64)\n",
        "  cl_maxvec = cl_array.empty(queue, 1, dtype = np.float64)\n",
        "  t2 = time()\n",
        "  opencl_grad(itr, A, b, matrix_size)\n",
        "  t3 = time()\n",
        "  tiempo_pyopen = t3 - t2\n",
        "  print(f'pyopencl method tarda: {tiempo_pyopen}')\n",
        "  return tiempo_power,tiempo_pyopen"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9iupt5fwFKL",
        "outputId": "21fad397-959c-4797-d958-13cdd95afdf9"
      },
      "source": [
        "tiempos_pyopen = []\n",
        "tiempos_power = []\n",
        "lista_dim_matrix = [1000]\n",
        "\n",
        "for k in lista_dim_matrix:\n",
        "  t_py, t_po = analizar_metodos(k, 30, 1000)\n",
        "  tiempos_power.append(t_po)\n",
        "  tiempos_pyopen.append(t_py)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "power method tarda: 0.020765066146850586\n",
            "1020\n",
            "pyopencl method tarda: 1.028076410293579\n"
          ]
        }
      ]
    }
  ]
}